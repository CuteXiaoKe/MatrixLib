<p>Gauss-Jordan reduction (or, Gaussian elimination, row reduction) plays a crucial role in implementing a number of algorithms in MatrixLib. This comes as no surprise, as Gauss-Jordan reduction is a central tenet of linear algebra. It is used for computing the rank and nullity of a matrix, solving systems represented by matrices, and a number of other applications.</p>
<p>This is particularly helpful if it is implemented with partial pivoting. In MatrixLib, at each row iteration, the row containing the pivot of highest magnitude is rotated up to the top. Then, when the steps involving subtracting multiples of that row from another are executed, the fact that this row has the largest pivot mitigates the effects of <a href="http://en.wikipedia.org/wiki/Loss_of_significance">catastrophic cancellation</a>. This pivoted Gauss-Jordan reduction algorithm is more numerically stable than the classical implementation.</p>
<p>One of the main benefits of having Gauss-Jordan at our disposal is the ability to compute determinants efficiently by an algorithm that is easily implemented. The standard method of computing determinants, through expanding the cofactors, has a highly undesirable asymptotic time complexity of $$O(n!)$$. But as it turns out, computing the determinant is as simple as row reducing the matrix, and this stems from the fundamental properties of the determinant.</p>
<p>MatrixLib implements computing the determinant as follows. Start with the matrix whose determinant we wish to compute and $$det=1$$. Now, any time the Gauss-Jordan algorithm swaps two rows, negate $$det$$ (the determinant is antisymmetric, meaning that swapping the rows of a matrix negates it). Any time the algorithm multiplies a row by $$x$$, divide $$det$$  by $$x$$. Finally, whenever the algorithm adds a multiple of one row to another, do nothing to $$det$$, since adding a multiple of one row to another in the matrix does not affect the determinant (the determinant is multlinear). Now, if the row-reduced matrix is the identity matrix, return $$det$$. On the other hand, if the matrix has been row-reduced to a matrix that is not the identity matrix, the original matrix was not invertible, and we return zero.</p>
<p>Viewed more mathematically, every row operation can be represented by multiplying the matrix by an elementary matrix $$E_i$$. If $$\tilde{A}$$ is the row-reduced matrix, we then have $$\tilde{A}=E_n\cdots E_1A$$, or</p>
<p>\[\det(A)=\frac{\det(\tilde{A})}{\det(E_n)\cdots\det(E_1)}.\]</p>
<p>If $$A$$ is invertible, $$\tilde{A}=I$$ and thus has determinant 1. Otherwise, it has at least one row of zeros and thus has determinant zero. Each elementary matrix has a determinant described above as its associated operation's effect on $$det$$.</p>
<p>It can be shown that Gauss-Jordan reduction (and thus our algorithm for computing determinants) has asymptotic time complexity $$O(n^3)$$, which is enormously better than the efficiency of the cofactor expansion algorithm. This seems to be the best way to compute the determinant of a matrix. Other common methods involve computing a factorization of the matrix first; of the four major ones implemented in MatrixLib currently, only QR and Schur decomposition work for every matrix. QR decomposition writes a matrix as a product of a unitary matrix and a right triangular matrix. The determinant of the triangular matrix is just the product along the diagonal, but the determinant of the unitary matrix can be either 1 or -1, so this is really only good for telling us the absolute value of the determinant. Computing the determinant via Schur decomposition avoids this problem, but Schur decomposition relies on computing the eigenvalues of the matrix, which can be a relatively long and imprecise process.</p>